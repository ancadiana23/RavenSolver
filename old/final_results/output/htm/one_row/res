Run windows
Run problems
Test
0
0.850965640973 0.0234425796411 *
0.0 0.0 
0.199582684319 0.00606634298843 
0.0 0.0 
0.124494392658 0.00377255735326 
0.0460004953202 0.00163702830321 



4
0.196034171619 0.00540039040271 
0.0673162478488 0.00168712400624 
0.859077576781 0.0261117804493 
0.10321177775 0.00307177909971 
0.147389722988 0.00446635524206 *
0.144218298839 0.00513232380211 



3
0.486553802388 0.00160897421425 
0.0 0.0 
0.0 0.0 
0.0 0.0 *
0.914034502115 0.0409880942653 
0.0 0.0 



5
0.55813293939 0.0078832336072 
0.396773232846 0.00552608959395 
0.118205606006 0.00161703975385 
0.307077268139 0.00438681811626 
0.458798801177 0.00667829404916 
0.202537111589 0.0031159555629 *



3
0.86694424897 0.00345396115127 
0.616290473172 0.00172921008185 
0.301308964386 0.00572830730773 
0.926742412536 0.00262384601511 *
0.864821019426 0.00198535587563 
0.89120200984 0.00247762582663 



0
0.0544835684123 0.00105999160335 *
0.199837991269 0.00508493616461 
0.0505658066832 0.00109925666703 
0.912956625223 0.016302796879 
0.0755274740513 0.00133205421607 
0.0658157194266 0.001162821898 



3
0.95430056355 0.0242824570878 
0.982240232755 0.011238446599 
0.954632277135 0.00688767876721 
0.968167657731 0.00714514876554 *
0.976103493595 0.00511048949526 
0.550182424369 0.00251339618259 



2
0.536630723625 0.0161635760128 
0.246644847095 0.00690881924636 
0.178463697201 0.00545760541898 *
0.1576071335 0.00449023172365 
0.624501620652 0.0193944602687 
0.189277756959 0.00551830195216 



1
0.0547523299465 0.00182507766488 
0.584639969165 0.0179889221282 *
0.0684449037071 0.00248890558935 
0.103487466113 0.00204520684017 
0.826112198178 0.0153838398171 
0.0801098013762 0.00270641220866 



5
0.34566420177 0.0233556893088 
0.094221156789 0.00346401311724 
0.22523475741 0.0180187805928 
0.987921744585 0.052270991777 
0.0 0.0 
0.0 0.0 *



1
0.817327167839 0.017206887744 
0.634691311163 0.0133058975087 *
0.365787650109 0.00823846058805 
0.207796821021 0.00440247502164 
0.544345193193 0.0131484346182 
0.629405300831 0.019189186001 



4
0.700803831074 0.00268096339355 
0.699207789032 0.00197795697039 
0.638790602155 0.00282901063842 
0.81393290151 0.00775913156826 
0.723136934103 0.00265663825901 *
0.755508447794 0.00209514267275 



1
0.29409778025 0.00939609521566 
0.103163245134 0.00317425369643 *
0.0 0.0 
0.0 0.0 
0.652780272067 0.0211941646775 
0.0475328355096 0.00166781878981 



3
0.892447715858 0.0151776822425 
0.541991444654 0.00910909991015 
0.321564376471 0.00539537544414 
0.468764603371 0.00754854433769 *
0.609937799512 0.010048398674 
0.691867475514 0.0116280247986 



5
0.0 0.0 
0.0 0.0 
0.00804866012186 0.000292678549886 
0.00804866012186 0.000293746719776 
0.00804866012186 0.000285413479499 
0.00804866012186 0.000291618120357 *



3
0.0217747357674 0.00156652775305 
0.042496947106 0.00307948892072 
0.052638588706 0.00360538278808 
0.0446865465492 0.00326179171892 *
0.051640330581 0.00346579399872 
0.0502635966986 0.00351493683207 



0
0.594898350304 0.00646628641635 *
0.859077569097 0.0261117802157 
0.742531643715 0.00784088324936 
0.476017364301 0.00315243287616 
0.268099987879 0.00298885159286 
0.285156955011 0.00305307232346 



2
0.85744817293 0.0155899667805 
0.00653942159261 0.000302750999658 
0.211079078843 0.00653495600133 *
0.177642160794 0.00359599515777 
0.837529821147 0.0185294208218 
0.147658062575 0.00479409294074 



1
0.200345595367 0.00392065744359 
0.164155018982 0.00328310037963 *
0.237070692237 0.0058535973392 
0.102463415358 0.00307697944019 
0.218502364587 0.00874009458348 
0.175379088614 0.00666840641118 



0
0.101558457362 0.00419663046948 *
0.37924385583 0.0151093169653 
0.461637192173 0.017755276622 
0.462940131547 0.0153800708155 
0.456707150908 0.0159131411466 
0.0748480658513 0.00260794654534 



4
0.415305032569 0.00147166914447 
0.0403766871023 0.00132382580663 
0.877024760528 0.0317762594394 
0.31296047158 0.00173385302814 
0.870955868042 0.00278082971916 *
0.161328893068 0.00523795107362 



0
0.126129623968 0.00462013274609 *
0.187982622767 0.00846768571022 
0.276347325533 0.0107111366486 
0.848835044308 0.0307548929097 
0.321873091045 0.0118772358319 
0.299885017448 0.0119001991051 



2
0.130903575919 0.00430603868153 
0.0632358853472 0.00292758728459 
0.614166849991 0.0222524221011 *
0.236701910602 0.0134489721933 
0.913632201831 0.0202131018104 
0.192573466818 0.00365414548043 



1
0.14250517427 0.00293825101587 
0.20735360356 0.00467012620632 *
0.112804419128 0.00419347283005 
0.036399722565 0.00131883052772 
0.286566253286 0.00887202022557 
0.13625051151 0.00431172504779 



5
0.344284058607 0.004742204664 
0.799045895226 0.0103235903776 
0.148815121967 0.00177795844644 
0.11442654737 0.00160261270827 
0.209150772833 0.00325273363659 
0.229196892178 0.00301574858129 *



1
0.0547523297137 0.00182507765712 
0.584639968118 0.0179889220959 *
0.0684449048713 0.00248890563168 
0.103487466578 0.00204520684937 
0.826112197363 0.0153838398019 
0.0365764910821 0.00133979820814 



5
0.0357515555806 0.0013095807905 
0.0183793827891 0.000827900125637 
0.0330744883977 0.00128195691464 
0.0330744883977 0.0011983510289 
0.0337123339996 0.00124399756456 
0.0401560077444 0.00159349237081 *



4
0.20472530718 0.0187821382734 
0.225373944268 0.00856935149307 
0.0 0.0 
0.883421171457 0.0825627263044 
0.922129235696 0.0374849282803 *
0.824231624603 0.0249767158971 



[ 0.02344258  0.          0.          0.          0.          0.          0.
  0.          0.01798892  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.          0.
  0.          0.02225242  0.          0.          0.01798892  0.00159349
  0.        ]
(5, 28)
0.297379779776

real	44m16.916s
user	44m16.168s
sys	0m0.636s

========================================================


BTM(numberOfCols=num_colls1, cellsPerColumn=10,
                initialPerm=0.5, connectedPerm=0.5,
                minThreshold=10, newSynapseCount=10,
                activationThreshold=10,
                pamLength=10)


=======================================================

def test_2(layers, problems):
    correct_predictions = np.zeros(len(problems))
    num_correct_predictions = 0
    windows = parse_images.get_windows(problems)


    print("Run windows")

    for _ in range(2):
        for i in np.random.permutation(len(windows)):
            run_through_network(layers, windows[i], True)
            run_through_network(layers, windows[i], True)
            layers[-1][0].reset()

    print("Run problems")
    for _ in range(5):
        for i in np.random.permutation(len(problems)):
            run_through_network(layers, problems[i]['Input'][0], True)
            run_through_network(layers, problems[i]['Input'][1], True)
            layers[-1][0].reset()

    print("Test")
    for i in range(len(problems)):
        for _ in range(10):
            run_through_network(layers, problems[i]['Input'][0], True)
            run_through_network(layers, problems[i]['Input'][1], True)
            layers[-1][0].reset()

        run_through_network(layers, problems[i]['Input'][2], False)
        predict = layers[-1][0].predict(1)
        # correct answer
        res_idx = problems[i]['Attributes']['result'] - 1
        print(res_idx)

        matches = np.zeros(len(problems[i]['Output']))
        for j in range(len(problems[i]['Output'])):
            # run the window through all but the last layer
            last_input = run_through_network(layers[:-1], problems[i]['Output'][j], False)
            # compare the result with the predicted state

            matches[j] = np.sum(last_input * predict) * 10.0 / np.sum(last_input)
            print np.sum(last_input * predict), matches[j],
            if j == res_idx:
                print "*"
            else:
                print ""

        #print(problems[i]['Attributes']['title'], matches)
        vote = np.argmax(matches)

        # if the precition was correct add it to the correct_predictions list
        if vote == res_idx and np.max(matches) > 0.0:
            correct_predictions[i] = np.max(matches)
            num_correct_predictions += 1

        run_through_network(layers, problems[i]['Output'][vote], False)
        layers[-1][0].reset()
        print('\n\n')

        # write output
        with open('output/htm/one_row/' + str(i), 'w+') as f:
            for win in problems[i]['Input']:
                size = int(len(win) ** 0.5)
                for line in win.reshape((size, size)):
                    f.write(''.join([str(x) for x in line]) + '\n')
                f.write('\n')
            m = np.mean(predict)
            for line in predict.reshape((size, size)):
                f.write(''.join([str(int(x >= m)) for x in line]) + '\n')
            f.write('\n')

